import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import davies_bouldin_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load the datasets
customers = pd.read_csv("Customers.csv")
transactions = pd.read_csv("Transactions.csv")

# Merge datasets for clustering
data = transactions.merge(customers, on='CustomerID', how='left')

# Feature Engineering
# Calculate customer lifetime (days since signup)
data['SignupDate'] = pd.to_datetime(data['SignupDate'])
data['Tenure'] = (pd.to_datetime('today') - data['SignupDate']).dt.days

# Aggregate transaction data by customer
customer_data = data.groupby('CustomerID').agg({
    'TotalValue': 'sum',  # Total revenue per customer
    'Quantity': 'sum',    # Total quantity purchased
    'Tenure': 'max',      # Customer tenure
    'Region': 'first'     # Region
}).reset_index()

# Encode categorical variable (Region)
le = LabelEncoder()
customer_data['RegionEncoded'] = le.fit_transform(customer_data['Region'])

# Select features for clustering
features = customer_data[['TotalValue', 'Quantity', 'Tenure', 'RegionEncoded']]
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

# Clustering using K-Means
k_values = range(2, 11)
db_scores = []

for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42)
    clusters = kmeans.fit_predict(scaled_features)
    db_index = davies_bouldin_score(scaled_features, clusters)
    db_scores.append(db_index)
    print(f"K={k}, DB Index={db_index:.2f}")

# Optimal number of clusters
optimal_k = k_values[np.argmin(db_scores)]
print(f"Optimal number of clusters: {optimal_k}")

# Final clustering with optimal K
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
customer_data['Cluster'] = kmeans.fit_predict(scaled_features)

# Visualize Clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(
    x=scaled_features[:, 0], y=scaled_features[:, 1],
    hue=customer_data['Cluster'], palette='tab10', s=50
)
plt.title("Customer Segmentation")
plt.xlabel("Scaled Total Value")
plt.ylabel("Scaled Quantity")
plt.legend(title='Cluster')
plt.show()

# Output clustering metrics and results
print("Final Clustering Results:")
print(customer_data[['CustomerID', 'Cluster']].head())

# Save to CSV
customer_data[['CustomerID', 'Cluster']].to_csv("Clustering_Results.csv", index=False)